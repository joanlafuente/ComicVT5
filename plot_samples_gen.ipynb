{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlafuente/anaconda3/envs/comicsgen/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import argparse\n",
    "import importlib\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import evaluate\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from src.common.configuration import get_dataset_configuration, get_model_configuration\n",
    "from src.datasets.comics_dialogue_generation import ComicsDialogueGenerationDataset\n",
    "# from src.datasets.comics_images_Sim_CLR_text import ComicsImageTextDataset, create_test_dataset\n",
    "from src.datasets.comics_dialogue_generation_1_description_panel import create_test_dataset\n",
    "from src.models.dialogue_generation_vlt5 import DialogueGenerationVLT5Model\n",
    "from src.tokenizers.vlt5_tokenizers import VLT5TokenizerFast\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser(description='Plotting script')\n",
    "\n",
    "    parser.add_argument('--model', type=str, default=\"dialogue_generation_vlt5_inf\",\n",
    "                        help='Model to run')\n",
    "    parser.add_argument('--load_cloze_checkpoint', type=str,  default=\"/home/jlafuente/Comics_dialogs_generation/runs/DialogueGenerationVLT5Model_comics_dialogue_generation_1_description_panel_2024-02-09_00:43:43/models/epoch_7.pt\",\n",
    "                        help='Path to text cloze model checkpoint')\n",
    "    parser.add_argument('--dataset_config', type=str, default=\"comics_dialogue_generation_textract_Blip2\",\n",
    "                        help='Dataset config to use')\n",
    "    parser.add_argument('--dataset_dir', type=str, default=\"/data/data/datasets/COMICS\",\n",
    "                        help='Dataset directory path')\n",
    "    parser.add_argument('--output_dir', type=str, default=\"plots_textract_gen/\",\n",
    "                        help='Output directory path')\n",
    "    parser.add_argument('--sample_id', type=int, default=275,\n",
    "                        help='Sample id to plot')\n",
    "    parser.add_argument('--seed', type=int, default=4,\n",
    "                        help='Random seed')\n",
    "\n",
    "    return parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n",
    "    model.load_checkpoint(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_arguments()\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text_cloze_config = get_model_configuration(args.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DialogueGenerationVLT5Model(\n",
       "  (shared): Embedding(32200, 768)\n",
       "  (encoder): JointEncoder(\n",
       "    (embed_tokens): Embedding(32200, 768)\n",
       "    (visual_embedding): VisualEmbedding(\n",
       "      (feat_embedding): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (1): T5LayerNorm()\n",
       "      )\n",
       "      (absolute_vis_pos_embedding): Sequential(\n",
       "        (0): Linear(in_features=5, out_features=768, bias=True)\n",
       "        (1): T5LayerNorm()\n",
       "      )\n",
       "      (obj_order_embedding): Embedding(32200, 768)\n",
       "      (img_order_embedding): Embedding(4, 768)\n",
       "    )\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32200, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32200, bias=False)\n",
       "  (linear_projection): Linear(in_features=768, out_features=2048, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelClass = getattr(importlib.import_module(\n",
    "    f\"src.models.{args.model}\"), model_text_cloze_config.classname)\n",
    "model_text_cloze = ModelClass(model_text_cloze_config, device).to(device)\n",
    "load_checkpoint(args.load_cloze_checkpoint, model_text_cloze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'VLT5TokenizerFast'.\n",
      "/home/jlafuente/anaconda3/envs/comicsgen/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = VLT5TokenizerFast.from_pretrained(\n",
    "                model_text_cloze_config.backbone,\n",
    "                max_length=model_text_cloze_config.max_text_length,\n",
    "                do_lower_case=model_text_cloze_config.do_lower_case,\n",
    "            )\n",
    "dataset_config = get_dataset_configuration(args.dataset_config)\n",
    "dataset_config[\"test\"] = True\n",
    "df, dataset = create_test_dataset(args.dataset_dir, device, dataset_config, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of dialogue generation \n",
    "Without candidates in the encoder inpout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ah! there he goes!\n",
      "Prediction: i'll have to, dick. i'll have to. i '\n"
     ]
    }
   ],
   "source": [
    "model_text_cloze.eval()\n",
    "with torch.no_grad():\n",
    "    for i, sample_data in enumerate(dataloader):\n",
    "        args.sample_id = sample_data[\"sample_id\"]\n",
    "    \n",
    "        sample_data = {key: value.type(torch.float32) if value.dtype == torch.float64 else value for key, value in sample_data.items() if isinstance(value, torch.Tensor)}\n",
    "\n",
    "        output = model_text_cloze.run(**sample_data)\n",
    "        prediction_text_cloze = tokenizer.decode(output[\"prediction\"][0], skip_special_tokens=True)\n",
    "        print(f\"Prediction: {prediction_text_cloze}\")\n",
    "        if i == 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>page_id</th>\n",
       "      <th>context_panel_0_id</th>\n",
       "      <th>context_panel_1_id</th>\n",
       "      <th>context_panel_2_id</th>\n",
       "      <th>answer_panel_id</th>\n",
       "      <th>context_text_0_0</th>\n",
       "      <th>context_text_0_1</th>\n",
       "      <th>context_text_0_2</th>\n",
       "      <th>context_text_1_0</th>\n",
       "      <th>context_text_1_1</th>\n",
       "      <th>context_text_1_2</th>\n",
       "      <th>context_text_2_0</th>\n",
       "      <th>context_text_2_1</th>\n",
       "      <th>context_text_2_2</th>\n",
       "      <th>answer_candidate_0_text</th>\n",
       "      <th>answer_candidate_1_text</th>\n",
       "      <th>answer_candidate_2_text</th>\n",
       "      <th>correct_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3451</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>pepper sprinkled on the trail! the hound's no ...</td>\n",
       "      <td>alertly watching for footprints and other sign...</td>\n",
       "      <td>ow! my foot!</td>\n",
       "      <td>ouch! doggoned thing drove right through my sole!</td>\n",
       "      <td>why, the trail is studded with 'em!</td>\n",
       "      <td></td>\n",
       "      <td>i'll have to drop out, dick.. can't keep up to...</td>\n",
       "      <td>tough luck, simba. i'll push on. tell the othe...</td>\n",
       "      <td></td>\n",
       "      <td>championship and prog ! i don ' t get it ! wou...</td>\n",
       "      <td>speaking of the rifle look its gone !</td>\n",
       "      <td>marked repair wheel boys , and even the fire d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  page_id  context_panel_0_id  context_panel_1_id  \\\n",
       "1     3451        6                   1                   2   \n",
       "\n",
       "   context_panel_2_id  answer_panel_id  \\\n",
       "1                   3                4   \n",
       "\n",
       "                                    context_text_0_0  \\\n",
       "1  pepper sprinkled on the trail! the hound's no ...   \n",
       "\n",
       "                                    context_text_0_1 context_text_0_2  \\\n",
       "1  alertly watching for footprints and other sign...     ow! my foot!   \n",
       "\n",
       "                                    context_text_1_0  \\\n",
       "1  ouch! doggoned thing drove right through my sole!   \n",
       "\n",
       "                      context_text_1_1 context_text_1_2  \\\n",
       "1  why, the trail is studded with 'em!                    \n",
       "\n",
       "                                    context_text_2_0  \\\n",
       "1  i'll have to drop out, dick.. can't keep up to...   \n",
       "\n",
       "                                    context_text_2_1 context_text_2_2  \\\n",
       "1  tough luck, simba. i'll push on. tell the othe...                    \n",
       "\n",
       "                             answer_candidate_0_text  \\\n",
       "1  championship and prog ! i don ' t get it ! wou...   \n",
       "\n",
       "                 answer_candidate_1_text  \\\n",
       "1  speaking of the rifle look its gone !   \n",
       "\n",
       "                             answer_candidate_2_text  correct_answer  \n",
       "1  marked repair wheel boys , and even the fire d...               0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[args.sample_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book id: 3451\n",
      "Page id: 6\n",
      "Target text: championship and prog ! i don ' t get it ! would cooperate criminals use such sometime ?\n"
     ]
    }
   ],
   "source": [
    "sample = dict(df.iloc[args.sample_id])\n",
    "book_id = int(sample[\"book_id\"])\n",
    "page_id = int(sample[\"page_id\"])\n",
    "target_text = sample[f\"answer_candidate_{int(sample['correct_answer'])}_text\"].iloc[0]\n",
    "print(f\"Book id: {book_id}\")\n",
    "print(f\"Page id: {page_id}\")\n",
    "print(f\"Target text: {target_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of dialogue generation \n",
    "Without candidates in the encoder inpout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECT_COLOR = (0, 1, 0)\n",
    "INCORRECT_COLOR = (1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "# setting values to rows and column variables\n",
    "rows = 2\n",
    "columns = 4\n",
    "# reading images\n",
    "Image1 = cv2.imread(\n",
    "    f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"context_panel_0_id\"])}.jpg')\n",
    "Image1 = cv2.cvtColor(Image1, cv2.COLOR_BGR2RGB)\n",
    "Image2 = cv2.imread(\n",
    "    f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"context_panel_1_id\"])}.jpg')\n",
    "Image2 = cv2.cvtColor(Image2, cv2.COLOR_BGR2RGB)\n",
    "Image3 = cv2.imread(\n",
    "    f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"context_panel_2_id\"])}.jpg')\n",
    "Image3 = cv2.cvtColor(Image3, cv2.COLOR_BGR2RGB)\n",
    "Image4 = cv2.imread(\n",
    "    f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"answer_panel_id\"])}.jpg')\n",
    "Image4 = cv2.cvtColor(Image4, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Adds a subplot at the 1st position\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "\n",
    "# showing image\n",
    "plt.imshow(Image1)\n",
    "plt.axis('off')\n",
    "plt.title(\"Context panel 1\")\n",
    "\n",
    "# Adds a subplot at the 2nd position\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "\n",
    "# showing image\n",
    "plt.imshow(Image2)\n",
    "plt.axis('off')\n",
    "plt.title(\"Context panel 2\")\n",
    "\n",
    "# Adds a subplot at the 3rd position\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "\n",
    "# showing image\n",
    "plt.imshow(Image3)\n",
    "plt.axis('off')\n",
    "plt.title(\"Context panel 3\")\n",
    "\n",
    "# Adds a subplot at the 4th position\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "\n",
    "# showing image\n",
    "plt.imshow(Image4)\n",
    "plt.axis('off')\n",
    "plt.title(\"Answer panel\")\n",
    "\n",
    "# Adding a subplot at the 5th to 7th position\n",
    "for i in range(1, 5):\n",
    "    fig.add_subplot(rows, columns, i+4)\n",
    "    if i <= 3:\n",
    "        # showing text\n",
    "        color = CORRECT_COLOR if i - 1 == int(sample[\"correct_answer\"]) else INCORRECT_COLOR\n",
    "        content = sample[f\"answer_candidate_{i-1}_text\"].iloc[0]\n",
    "        plt.title(f\"Candidate {i}\")\n",
    "        txt = plt.text(0.5, 0.5, content, fontsize=14, wrap=True,\n",
    "                        ha=\"center\", va=\"top\", color=color)\n",
    "        txt._get_wrap_line_width = lambda: 300.\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        # showing text\n",
    "        plt.title(\"Predicted text\")\n",
    "        txt = plt.text(0.5, 0.5, prediction_text_cloze, fontsize=14, wrap=True,\n",
    "                        ha=\"center\", va=\"top\", color=(0, 0, 0))\n",
    "        txt._get_wrap_line_width = lambda: 300.\n",
    "        plt.axis('off')\n",
    "\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "plt.savefig(f'{args.output_dir}/{args.dataset_config.split(\"_\")[-1]}_{args.sample_id}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over the test set \n",
    "Generating an image of the prediction for each 25 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save the plots\n",
    "args.output_dir = \"plots_easy_vlt5_textract_blip2_gen/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "CORRECT_COLOR = (0, 1, 0)\n",
    "INCORRECT_COLOR = (1, 0, 0)\n",
    "\n",
    "model_text_cloze.eval()\n",
    "model_text_cloze.to(device)\n",
    "for sample_data in tqdm(dataloader):\n",
    "    args.sample_id = int(sample_data[\"sample_id\"][0])\n",
    "    # Make the plot every 25 samples\n",
    "    if args.sample_id % 25 == 0:\n",
    "        sample_data = {key: value.type(torch.float32) if value.dtype == torch.float64 else value for key, value in sample_data.items() if isinstance(value, torch.Tensor)}\n",
    "\n",
    "        output = model_text_cloze.run(**sample_data)\n",
    "        prediction_text_cloze = tokenizer.decode(output[\"prediction\"][0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "        sample = dict(df.iloc[args.sample_id])\n",
    "        book_id = int(sample[\"book_id\"])\n",
    "        page_id = int(sample[\"page_id\"])\n",
    "        target_text = sample[f\"answer_candidate_{int(sample['correct_answer'])}_text\"]\n",
    "\n",
    "        # Plot sample\n",
    "        fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "        # setting values to rows and column variables\n",
    "        rows = 2\n",
    "        columns = 4\n",
    "        # reading images\n",
    "        Image1 = cv2.imread(\n",
    "            f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"context_panel_0_id\"])}.jpg')\n",
    "        Image1 = cv2.cvtColor(Image1, cv2.COLOR_BGR2RGB)\n",
    "        Image2 = cv2.imread(\n",
    "            f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"context_panel_1_id\"])}.jpg')\n",
    "        Image2 = cv2.cvtColor(Image2, cv2.COLOR_BGR2RGB)\n",
    "        Image3 = cv2.imread(\n",
    "            f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"context_panel_2_id\"])}.jpg')\n",
    "        Image3 = cv2.cvtColor(Image3, cv2.COLOR_BGR2RGB)\n",
    "        Image4 = cv2.imread(\n",
    "            f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"answer_panel_id\"])}.jpg')\n",
    "        Image4 = cv2.cvtColor(Image4, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Adds a subplot at the 1st position\n",
    "        fig.add_subplot(rows, columns, 1)\n",
    "\n",
    "        # showing image\n",
    "        plt.imshow(Image1)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Context panel 1\")\n",
    "\n",
    "        # Adds a subplot at the 2nd position\n",
    "        fig.add_subplot(rows, columns, 2)\n",
    "\n",
    "        # showing image\n",
    "        plt.imshow(Image2)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Context panel 2\")\n",
    "\n",
    "        # Adds a subplot at the 3rd position\n",
    "        fig.add_subplot(rows, columns, 3)\n",
    "\n",
    "        # showing image\n",
    "        plt.imshow(Image3)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Context panel 3\")\n",
    "\n",
    "        # Adds a subplot at the 4th position\n",
    "        fig.add_subplot(rows, columns, 4)\n",
    "\n",
    "        # showing image\n",
    "        plt.imshow(Image4)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Answer panel\")\n",
    "\n",
    "        # Adding a subplot at the 5th to 7th position\n",
    "        for i in range(1, 5):\n",
    "            fig.add_subplot(rows, columns, i+4)\n",
    "            if i <= 3:\n",
    "                # showing text\n",
    "                color = CORRECT_COLOR if i - 1 == int(sample[\"correct_answer\"]) else INCORRECT_COLOR\n",
    "                content = sample[f\"answer_candidate_{i-1}_text\"]\n",
    "                plt.title(f\"Candidate {i}\")\n",
    "                txt = plt.text(0.5, 0.5, content, fontsize=14, wrap=True,\n",
    "                                ha=\"center\", va=\"top\", color=color)\n",
    "                txt._get_wrap_line_width = lambda: 300.\n",
    "                plt.axis('off')\n",
    "            else:\n",
    "                # showing text\n",
    "                plt.title(\"Predicted text\")\n",
    "                txt = plt.text(0.5, 0.5, prediction_text_cloze, fontsize=14, wrap=True,\n",
    "                                ha=\"center\", va=\"top\", color=(0, 0, 0))\n",
    "                txt._get_wrap_line_width = lambda: 300.\n",
    "                plt.axis('off')\n",
    "\n",
    "        # save the figure with the name of the sample and difficulty and metrics rounded to 2 decimal places\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "        plt.savefig(f'{args.output_dir}/{args.dataset_config.split(\"_\")[-1]}_{args.sample_id}.png')\n",
    "        # save the figure with the name of the sample and difficulty and metrics rounded to 2 decimal places\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "        plt.savefig(f'{args.output_dir}/{args.dataset_config.split(\"_\")[-1]}_{args.sample_id}.png')\n",
    "        # plt.show()\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating an image of the prediction for each 25 examples but only showing target and prediction\n",
    "Meant to be used with a dataset class that does not provide the posible answers in the encoder input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.output_dir = \"plots_easy_vlt5_textract_blip2_gen_only_pred_and_target/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "# setting values to rows and column variables\n",
    "rows = 2\n",
    "columns = 4\n",
    "# reading images\n",
    "Image1 = cv2.imread(\n",
    "    f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"context_panel_0_id\"])}.jpg')\n",
    "Image1 = cv2.cvtColor(Image1, cv2.COLOR_BGR2RGB)\n",
    "Image2 = cv2.imread(\n",
    "    f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"context_panel_1_id\"])}.jpg')\n",
    "Image2 = cv2.cvtColor(Image2, cv2.COLOR_BGR2RGB)\n",
    "Image3 = cv2.imread(\n",
    "    f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"context_panel_2_id\"])}.jpg')\n",
    "Image3 = cv2.cvtColor(Image3, cv2.COLOR_BGR2RGB)\n",
    "Image4 = cv2.imread(\n",
    "    f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"answer_panel_id\"])}.jpg')\n",
    "Image4 = cv2.cvtColor(Image4, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Adds a subplot at the 1st position\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "\n",
    "# showing image\n",
    "plt.imshow(Image1)\n",
    "plt.axis('off')\n",
    "plt.title(\"Context panel 1\")\n",
    "\n",
    "# Adds a subplot at the 2nd position\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "\n",
    "# showing image\n",
    "plt.imshow(Image2)\n",
    "plt.axis('off')\n",
    "plt.title(\"Context panel 2\")\n",
    "\n",
    "# Adds a subplot at the 3rd position\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "\n",
    "# showing image\n",
    "plt.imshow(Image3)\n",
    "plt.axis('off')\n",
    "plt.title(\"Context panel 3\")\n",
    "\n",
    "# Adds a subplot at the 4th position\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "\n",
    "# showing image\n",
    "plt.imshow(Image4)\n",
    "plt.axis('off')\n",
    "plt.title(\"Answer panel\")\n",
    "\n",
    "\n",
    "# Showing target\n",
    "fig.add_subplot(rows, columns, 5)\n",
    "content = sample[f\"answer_candidate_{int(sample['correct_answer'])}_text\"].iloc[0]\n",
    "plt.title(f\"Target text\")\n",
    "txt = plt.text(0.5, 0.5, content, fontsize=14, wrap=True,\n",
    "                ha=\"center\", va=\"top\", color=(0, 0, 0))\n",
    "txt._get_wrap_line_width = lambda: 300.\n",
    "plt.axis('off')\n",
    "\n",
    "# showing predicted text\n",
    "fig.add_subplot(rows, columns, 7)\n",
    "plt.title(\"Predicted text\")\n",
    "txt = plt.text(0.5, 0.5, prediction_text_cloze, fontsize=14, wrap=True,\n",
    "                ha=\"center\", va=\"top\", color=(0, 0, 0))\n",
    "txt._get_wrap_line_width = lambda: 300.\n",
    "plt.axis('off')\n",
    "\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "plt.savefig(f'{args.output_dir}/{args.dataset_config.split(\"_\")[-1]}_{args.sample_id}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterating over the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11909 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11909/11909 [10:07<00:00, 19.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "model_text_cloze.eval()\n",
    "model_text_cloze.to(device)\n",
    "for sample_data in tqdm(dataloader):\n",
    "    args.sample_id = int(sample_data[\"sample_id\"][0])\n",
    "    # Make the plot every 25 samples\n",
    "    if args.sample_id % 25 == 0:\n",
    "        sample_data = {key: value.type(torch.float32) if value.dtype == torch.float64 else value for key, value in sample_data.items() if isinstance(value, torch.Tensor)}\n",
    "\n",
    "        output = model_text_cloze.run(**sample_data)\n",
    "        prediction_text_cloze = tokenizer.decode(output[\"prediction\"][0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "        sample = dict(df.iloc[args.sample_id])\n",
    "        book_id = int(sample[\"book_id\"])\n",
    "        page_id = int(sample[\"page_id\"])\n",
    "        target_text = sample[f\"answer_candidate_{int(sample['correct_answer'])}_text\"]\n",
    "\n",
    "        # Plot sample\n",
    "        fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "        # setting values to rows and column variables\n",
    "        rows = 2\n",
    "        columns = 4\n",
    "        # reading images\n",
    "        Image1 = cv2.imread(\n",
    "            f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"context_panel_0_id\"])}.jpg')\n",
    "        Image1 = cv2.cvtColor(Image1, cv2.COLOR_BGR2RGB)\n",
    "        Image2 = cv2.imread(\n",
    "            f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"context_panel_1_id\"])}.jpg')\n",
    "        Image2 = cv2.cvtColor(Image2, cv2.COLOR_BGR2RGB)\n",
    "        Image3 = cv2.imread(\n",
    "            f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"context_panel_2_id\"])}.jpg')\n",
    "        Image3 = cv2.cvtColor(Image3, cv2.COLOR_BGR2RGB)\n",
    "        Image4 = cv2.imread(\n",
    "            f'{args.dataset_dir}/panels/{book_id}/{page_id}_{int(sample[\"answer_panel_id\"])}.jpg')\n",
    "        Image4 = cv2.cvtColor(Image4, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Adds a subplot at the 1st position\n",
    "        fig.add_subplot(rows, columns, 1)\n",
    "\n",
    "        # showing image\n",
    "        plt.imshow(Image1)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Context panel 1\")\n",
    "\n",
    "        # Adds a subplot at the 2nd position\n",
    "        fig.add_subplot(rows, columns, 2)\n",
    "\n",
    "        # showing image\n",
    "        plt.imshow(Image2)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Context panel 2\")\n",
    "\n",
    "        # Adds a subplot at the 3rd position\n",
    "        fig.add_subplot(rows, columns, 3)\n",
    "\n",
    "        # showing image\n",
    "        plt.imshow(Image3)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Context panel 3\")\n",
    "\n",
    "        # Adds a subplot at the 4th position\n",
    "        fig.add_subplot(rows, columns, 4)\n",
    "\n",
    "        # showing image\n",
    "        plt.imshow(Image4)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Answer panel\")\n",
    "\n",
    "        # Showing target\n",
    "        fig.add_subplot(rows, columns, 5)\n",
    "        content = sample[f\"answer_candidate_{int(sample['correct_answer'])}_text\"]\n",
    "        plt.title(f\"Target text\")\n",
    "        txt = plt.text(0.5, 0.5, content, fontsize=14, wrap=True,\n",
    "                        ha=\"center\", va=\"top\")\n",
    "        txt._get_wrap_line_width = lambda: 300.\n",
    "        plt.axis('off')\n",
    "\n",
    "        # showing predicted text\n",
    "        fig.add_subplot(rows, columns, 7)\n",
    "        plt.title(\"Predicted text\")\n",
    "        txt = plt.text(0.5, 0.5, prediction_text_cloze, fontsize=14, wrap=True,\n",
    "                        ha=\"center\", va=\"top\", color=(0, 0, 0))\n",
    "        txt._get_wrap_line_width = lambda: 300.\n",
    "        plt.axis('off')\n",
    "\n",
    "        # save the figure with the name of the sample and difficulty and metrics rounded to 2 decimal places\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "        plt.savefig(f'{args.output_dir}/{args.dataset_config.split(\"_\")[-1]}_{args.sample_id}.png')\n",
    "        # save the figure with the name of the sample and difficulty and metrics rounded to 2 decimal places\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "        plt.savefig(f'{args.output_dir}/{args.dataset_config.split(\"_\")[-1]}_{args.sample_id}.png')\n",
    "        # plt.show()\n",
    "        plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comicsgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
